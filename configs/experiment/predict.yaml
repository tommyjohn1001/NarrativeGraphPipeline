# @package _global_

defaults:
  - override /trainer: null # override trainer to null so it's not loaded from main config defaults...
  - override /model: null
  - override /datamodule: null
  - override /callbacks: null
  - override /logger: null

task: predict

trainer:
  _target_: pytorch_lightning.Trainer

  gpus: 1
  min_epochs: 1
  max_epochs: 1
  auto_lr_find: False
  terminate_on_nan: True
  log_every_n_steps: 50
  auto_scale_batch_size: False
  gradient_clip_val: 1.0
  accelerator: null
  precision: 16
  check_val_every_n_epoch: 2
  reload_dataloaders_every_epoch: True
  weights_summary: "top"
  progress_bar_refresh_rate: 5
  resume_from_checkpoint: ${PATH.checkpoint}

model:
  _target_: src.models.narrative_model.NarrativeModel

  len_ques: 42
  len_para: 170
  len_ans: 15
  n_paras: 5
  n_layers_trans: 3
  n_heads_trans: 4
  d_hid: 64
  d_bert: 768
  d_vocab: 30522
  lr: 1e-5
  w_decay: 1e-2
  switch_frequency: 5
  beam_size: 20
  n_gram_beam: 8

  path_bert: ${PATH.bert}
  path_pred: ${PATH.pred}
  path_train_pred: ${PATH.train_pred}

datamodule:
  _target_: src.datamodules.narrative_datamodule.NarrativeDataModule

  batch_size: ${batch_size}
  num_workers: ${num_workers}
  len_ques: 42
  len_para: 170
  len_para_processing: 120
  len_ans: 15
  sizes_dataset:
    train: 32747
    test: 10557
    valid: 3461

  path_bert: ${PATH.bert}
  path_data: ${PATH.data}
  path_raw_data: ${PATH.raw_data}
  path_processed_contx: ${PATH.processed_contx}
